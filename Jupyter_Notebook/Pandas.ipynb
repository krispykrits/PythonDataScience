{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit (windows store)"
  },
  "interpreter": {
   "hash": "5038e2a29891e2f6607a77391b92a300aeb01a0774b237f09770fc4a61edec80"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Explore Pandas as Series Structure"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "The series is one of the core data structures in pandas. Think of it as a cross between a list and dictionary. The items are stored in order and there's label in which you can retrieve them. As easy way to visualize this is two columns of data. The first column is the special index, similar to keys. While the second column is the actual data. It's important to note that the data column has a label on its own and can be retrieved using the .name attribute. This is different than with dictionaries and is useful when it comes to merging multiple columns of data. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    Alice\n",
       "1      Bob\n",
       "2     Jack\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "# We can create a series by passing a list of values. When we do this, pandas automatically assign an index starting with zero and sets the name of the series to None.\n",
    "\n",
    "# One of the easiest ways to create a series is to use an array-like object, like a list. \n",
    "\n",
    "students = [\"Alice\", \"Bob\", \"Jack\"]\n",
    "\n",
    "# Now we just call the series function in pandas and pass in the students\n",
    "\n",
    "pd.Series(students)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We see hare that pandas has automatically identifed the type of data in this Series as \"object\" and set the dtype parameter as appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "2    3\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "# If we passed in integers, we could see that pandas set the dtype to int64. Underneath panda stores series values in a typed array using the Numpy library. This offers a significant speedup when processing the data versus traditional python lists. \n",
    "\n",
    "numbers = [1, 2, 3]\n",
    "\n",
    "# And turn this into Series\n",
    "\n",
    "pd.Series(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    Alice\n",
       "1     Jack\n",
       "2     None\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# There's some other typing details that exist for performance that are important to know. The most important is how Numpy and thus pandas handle missing data. \n",
    "# If we create a list of strings and we have one element that is None type, pandas insert it as a None and uses the type object for the underlying array. \n",
    "\n",
    "# Example\n",
    "\n",
    "students = [\"Alice\", \"Jack\", None]\n",
    "\n",
    "pd.Series(students)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    1.0\n",
       "1    2.0\n",
       "2    3.0\n",
       "3    NaN\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "# If we create a list on integers or floating numbers and put in a none type, pandas will designate the None to NaN (Not a number) then pandas will set the numbers to float and cast the dtype to float64\n",
    "\n",
    "num = [1,2,3, None]\n",
    "\n",
    "pd.Series(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "# Nan is not equivalent to None \n",
    "\n",
    "import numpy as np \n",
    "np.nan == None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "# It turns out we can't do an equality to NaN to itself\n",
    "np.nan == np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "# Instead we need to use a special function to test for the precence of not a number. \n",
    "\n",
    "np.isnan(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Alice      Physics\n",
       "Jack     Chemistry\n",
       "Bob           Math\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "# A series can be directly created from dictionary data. If we do this, the index is automatically assigned to the keys of the dictionary we provided and not just incrementing integers\n",
    "\n",
    "student_scores = {\"Alice\": \"Physics\", \"Jack\": \"Chemistry\", \"Bob\": \"Math\"}\n",
    "s = pd.Series(student_scores)\n",
    "s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['Alice', 'Jack', 'Bob'], dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "# Once the series has been created, we can get the index of the object using the index attribute\n",
    "\n",
    "s.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    (Alice, Bob)\n",
       "1    (Jack, Mary)\n",
       "2    (Chris, Jen)\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "# The dtype object is not just for strings, but for arbitrary objects . \n",
    "# For example a list of tuples\n",
    "\n",
    "students = [(\"Alice\",\"Bob\"),(\"Jack\", \"Mary\"),(\"Chris\",\"Jen\")]\n",
    "pd.Series(students)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Jen        Physics\n",
       "Mary     Chemistry\n",
       "Chris         Math\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "# We can also separate the index creation from the data by passing in the index as a list explicitly to the series. \n",
    "\n",
    "s = pd.Series([\"Physics\",\"Chemistry\", \"Math\"], index=[\"Jen\",\"Mary\",\"Chris\"])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Alice       Math\n",
       "Jack         NaN\n",
       "Mary     English\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "# If the data in our list does not align with the keys, pandas overrides the creation to favor only and all of the indices values that we provided. So it will ignore from dictionary all keys which are not in our index, and pandas will provide Nan or None for any index value we provided, which is not in the dictionary list. \n",
    "\n",
    "# example\n",
    "\n",
    "student_scores = {\"Alice\": \"Math\", \"Bob\": \"Chem\", \"Mary\": \"English\"}\n",
    "\n",
    "s = pd.Series(student_scores, index=[\"Alice\",\"Jack\",\"Mary\"])\n",
    "s"
   ]
  },
  {
   "source": [
    "# Querying A Series"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    " A pandas Series can be queried either by the index position or the index label. If you don't give an index to the series when querying, the position and the label are effectively the same values. \n",
    " To query by numeric location, starting at zero, use the ***iloc*** attribute. \n",
    " To query by the index label, use the ***loc*** attribute "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Alice    Physics\n",
       "Bob         Chem\n",
       "Jack     English\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "students_classes = {\"Alice\": \"Physics\", \"Bob\": \"Chem\", \"Jack\": \"English\"}\n",
    "s = pd.Series(students_classes)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "English\nEnglish\n"
     ]
    }
   ],
   "source": [
    "# If we wanted to see the third entry, we would use the iloc attribute. We can also access the data by using [] operator\n",
    "\n",
    "print(s.iloc[2])\n",
    "print(s[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Chem\nChem\n"
     ]
    }
   ],
   "source": [
    "# If we wanted to see what class Bob has, we use the loc attribute.\n",
    "\n",
    "print(s.loc[\"Bob\"])\n",
    "print(s[\"Bob\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "99       Math\n",
       "100      Java\n",
       "101    Python\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "# If our custom index are list of integers, it is better to explicitly call the attributes with loc or iloc. \n",
    "\n",
    "# Here is an example using class and classcodes, where classes are indexed by classcodes in a form of integers. \n",
    "\n",
    "classcode = {99: \"Math\", 100: \"Java\", 101: \"Python\"}\n",
    "c = pd.Series(classcode)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Math'"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "# If we just call in c[0], the program will give an error because it is not in the key, therefore it is best to explicitly call iloc or loc\n",
    "\n",
    "c.iloc[0]"
   ]
  },
  {
   "source": [
    "## Working with Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "90.0\n"
     ]
    }
   ],
   "source": [
    "# For instance, create a series of students grades , and finding the average\n",
    "\n",
    "grades = pd.Series([80,90,100])\n",
    "\n",
    "total = 0\n",
    "\n",
    "for grade in grades:\n",
    "    total += grade\n",
    "print(total/len(grades))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "90.0\n"
     ]
    }
   ],
   "source": [
    "# This works, but it is slow. \n",
    "# Pandas and the underlying numpy libraries support a method of computation called vectorization. Vectorization works with most of the functions in the numpy library, including the sum function. \n",
    "\n",
    "total = np.sum(grades)\n",
    "print(total/len(grades))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0    960\n1    348\n2    470\n3    307\n4    289\ndtype: int32\n10000\n"
     ]
    }
   ],
   "source": [
    "# Both methods works, but which one is actually faster? The Jupyter notebook has a magic function that can help this. \n",
    "\n",
    "# First let's create a big series with random numbers\n",
    "numbers = pd.Series(np.random.randint(0,1000,10000))\n",
    "\n",
    "# We can check the first n items in the series by using the head() function\n",
    "print(numbers.head())\n",
    "\n",
    "# then verify that the length is correct\n",
    "print(len(numbers))"
   ]
  },
  {
   "source": [
    "# Magic Functions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Ok, we're confident now that we have a big series. The ipython interpreter has something called\n",
    "magic functions begin with a percentage sign. If we type this sign and then hit the Tab key, you\n",
    "can see a list of the available magic functions. You could write your own magic functions too, \n",
    "but that's a little bit outside of the scope of this course."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Here, we're actually going to use what's called a cellular magic function. These start with two \n",
    "percentage signs and wrap the code in the current Jupyter cell. The function we're going to use \n",
    "is called timeit. This function will run our code a few times to determine, on average, how long \n",
    "it takes.\n",
    "\n",
    "Let's run timeit with our original iterative code. You can give timeit the number of loops that \n",
    "you would like to run. By default, it is 1,000 loops. I'll ask timeit here to use 100 runs because \n",
    "we're recording this. Note that in order to use a cellular magic function, it has to be the first \n",
    "line in the cell"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\chrst\\\\OneDrive\\\\Python\\\\Jupyter_Notebook'"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.65 ms ± 973 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 100\n",
    "total = 0\n",
    "for number in numbers:\n",
    "    total += number\n",
    "\n",
    "total/len(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "141 µs ± 27.8 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 100\n",
    "total = np.sum(numbers)\n",
    "total/len(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wow! This is a pretty shocking difference in the speed and demonstrates why one should be \n",
    "# aware of parallel computing features and start thinking in functional programming terms.\n",
    "# Put more simply, vectorization is the ability for a computer to execute multiple instructions\n",
    "# at once, and with high performance chips, especially graphics cards, you can get dramatic\n",
    "# speedups. Modern graphics cards can run thousands of instructions in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    111\n",
       "1    225\n",
       "2    115\n",
       "3    362\n",
       "4    544\n",
       "dtype: int32"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "# A Related feature in pandas and nummy is called broadcasting. With broadcasting, you can \n",
    "# apply an operation to every value in the series, changing the series. For instance, if we\n",
    "# wanted to increase every random variable by 2, we could do so quickly using the += operator \n",
    "# directly on the Series object. \n",
    "\n",
    "# Let's look at the head of our series\n",
    "numbers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    113\n",
       "1    227\n",
       "2    117\n",
       "3    364\n",
       "4    546\n",
       "dtype: int32"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "# Now let's add 2\n",
    "\n",
    "numbers += 2\n",
    "numbers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The procedural way of doing this would be to iterate through all of the items in the \n",
    "# series and increase the values directly. Pandas does support iterating through a series \n",
    "# much like a dictionary, allowing you to unpack values easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "(0, 960)",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-651a97549068>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;31m# now for the item which is returned, lets call at()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mnumbers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;31m# And we can check the result of this computation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2154\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2156\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2158\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2102\u001b[0m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_key\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2103\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtakeable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_takeable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2105\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m    959\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    960\u001b[0m         \u001b[1;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 961\u001b[1;33m         \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    962\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    963\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\indexes\\range.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m    352\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 354\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    355\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: (0, 960)"
     ]
    }
   ],
   "source": [
    "# We can use the iteritems() function which returns a label and value \n",
    "for label, value in numbers.iteritems():\n",
    "    # now for the item which is returned, lets call at()\n",
    "    numbers.at[label, value]\n",
    "# And we can check the result of this computation\n",
    "numbers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So the result is the same, though you may notice a warning depending upon the version of\n",
    "# pandas being used. But if you find yourself iterating pretty much *any time* in pandas,\n",
    "# you should question whether you're doing things in the best possible way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets take a look at some speed comparisons. First, lets try five loops using the iterative approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "83.5 ms ± 17.3 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 10\n",
    "# we'll create a blank new series of items to deal with\n",
    "s = pd.Series(np.random.randint(0,1000,1000))\n",
    "# And we'll just rewrite our loop from above.\n",
    "for label, value in s.iteritems():\n",
    "    s.loc[label]= value+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's try that using broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The slowest run took 6.80 times longer than the fastest. This could mean that an intermediate result is being cached.\n776 µs ± 744 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 10\n",
    "s= pd.Series(np.random.randint(0,1000,1000))\n",
    "\n",
    "# And we just broadcast with +=\n",
    "\n",
    "s += 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amazing. Not only is it significantly faster, but it's more concise and even easier \n",
    "# to read too. The typical mathematical operations you would expect are vectorized, and the \n",
    "# nump documentation outlines what it takes to create vectorized functions of your own. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One last note on using the indexing operators to access series data. The .loc attribute lets \n",
    "# you not only modify data in place, but also add new data as well. If the value you pass in as \n",
    "# the index doesn't exist, then a new entry is added. And keep in mind, indices can have mixed types. \n",
    "# While it's important to be aware of the typing going on underneath, Pandas will automatically \n",
    "# change the underlying NumPy types as appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0            1\n",
       "1            2\n",
       "2            3\n",
       "History    102\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "# Here's an example using a Series of a few numbers. \n",
    "s = pd.Series([1, 2, 3])\n",
    "\n",
    "# We could add some new value, maybe a university course\n",
    "s.loc['History'] = 102\n",
    "\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We see that mixed types for data values or index labels are no problem for Pandas. Since \n",
    "# \"History\" is not in the original list of indices, s.loc['History'] essentially creates a \n",
    "# new element in the series, with the index named \"History\", and the value of 102"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Alice      Physics\n",
       "Jack     Chemistry\n",
       "Molly      English\n",
       "Sam        History\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "# Up until now I've shown only examples of a series where the index values were unique. I want \n",
    "# to end this lecture by showing an example where index values are not unique, and this makes \n",
    "# pandas Series a little different conceptually then, for instance, a relational database.\n",
    "\n",
    "# Lets create a Series with students and the courses which they have taken\n",
    "students_classes = pd.Series({'Alice': 'Physics',\n",
    "                   'Jack': 'Chemistry',\n",
    "                   'Molly': 'English',\n",
    "                   'Sam': 'History'})\n",
    "students_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Kelly    Philosophy\n",
       "Kelly          Arts\n",
       "Kelly          Math\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "# Now lets create a Series just for some new student Kelly, which lists all of the courses\n",
    "# she has taken. We'll set the index to Kelly, and the data to be the names of courses.\n",
    "kelly_classes = pd.Series(['Philosophy', 'Arts', 'Math'], index=['Kelly', 'Kelly', 'Kelly'])\n",
    "kelly_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Alice       Physics\n",
       "Jack      Chemistry\n",
       "Molly       English\n",
       "Sam         History\n",
       "Kelly    Philosophy\n",
       "Kelly          Arts\n",
       "Kelly          Math\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "# Finally, we can append all of the data in this new Series to the first using the .append()\n",
    "# function.\n",
    "all_students_classes = students_classes.append(kelly_classes)\n",
    "\n",
    "# This creates a series which has our original people in it as well as all of Kelly's courses\n",
    "all_students_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Alice      Physics\n",
       "Jack     Chemistry\n",
       "Molly      English\n",
       "Sam        History\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "# There are a couple of important considerations when using append. First, Pandas will take \n",
    "# the series and try to infer the best data types to use. In this example, everything is a string, \n",
    "# so there's no problems here. Second, the append method doesn't actually change the underlying Series\n",
    "# objects, it instead returns a new series which is made up of the two appended together. This is\n",
    "# a common pattern in pandas - by default returning a new object instead of modifying in place - and\n",
    "# one you should come to expect. By printing the original series we can see that that series hasn't\n",
    "# changed.\n",
    "students_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Kelly    Philosophy\n",
       "Kelly          Arts\n",
       "Kelly          Math\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "# Finally, we see that when we query the appended series for Kelly, we don't get a single value, \n",
    "# but a series itself. \n",
    "all_students_classes.loc['Kelly']"
   ]
  },
  {
   "source": [
    "In this lecture, we focused on one of the primary data types of the Pandas library, the Series. You learned how to query the Series, with .loc and .iloc, that the Series is an indexed data structure, how to merge two Series objects together with append(), and the importance of vectorization.\n",
    "\n",
    "There are many more methods associated with the Series object that we haven't talked about. But with these basics down, we'll move on to talking about the Panda's two-dimensional data structure, the DataFrame. The DataFrame is very similar to the series object, but includes multiple columns of data, and is the structure that you'll spend the majority of your time working with when cleaning and aggregating data."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}